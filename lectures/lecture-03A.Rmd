---
title: "ETC5521: Exploratory Data Analysis"
subtitle: "Initial data analysis: Model dependent exploration and how it differs from EDA"
author: "Emi Tanaka"
email: "ETC5521.Clayton-x@monash.edu"
date: "Week 3 - Session 1"
length: "10 minutes"
color_theme: "yellow"
bgimg: "images/steve-johnson--auJqHRvM_k-unsplash.jpg"
output:
  xaringan::moon_reader:
    css:
      - ninjutsu 
      - "assets/animate.css"
      - "assets/fira-code.css"
      - "assets/boxes.css"
      - "assets/styles.css"
      - "assets/custom.css"
      - "assets/monash-logo.css"
      - "assets/monash-brand.css"
      - "assets/monash-fonts.css"
      - "assets/table.css"
      - "assets/emi.css"
    self_contained: false 
    seal: false 
    chakra: 'libs/remark-latest.min.js'
    lib_dir: libs
    includes:
      in_header: "assets/custom.html"
    mathjax: "assets/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
    nature:
      highlightStyle: github
      highlightLanguage: r 
      highlightLines: true
      highlightSpans: false 
      countIncrementalSlides: false
      slideNumberFormat: '%current%/%total%'
      navigation:
        scroll: false 
        touch: true
        click: false
      ratio: '16:9'
---

```{r, include = FALSE}
current_file <- knitr::current_input()
```
```{r, include = FALSE, eval = F}
input <- fs::path_ext_set(current_file, "html")
pagedown::chrome_print(input = input, format = "pdf", wait = 20)
```

```{r, include = FALSE}
library(tidyverse)
library(colorspace)
options(width = 200)
knitr::opts_chunk$set(
  fig.path = "images/week3A/",
  fig.width = 6,
  fig.height = 4,
  fig.align = "center",
  #out.width = "100%",
  fig.retina = 3,
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  cache = FALSE
)
theme_set(ggthemes::theme_gdocs(base_size = 18) +
            theme(plot.background = element_blank(), axis.line.y = element_line(color = "black", linetype = "solid")
                  ) )
```


```{r titleslide, child="components/titleslide.Rmd"}
```

---

class: transition middle

## Exploratory Data Analysis

<br>

## (EDA)

--

<br>

.pull-right[So what is *non*-exploratory data analysis?]

`r countdown::countdown(3, class = "clock")`


---

# Data Analysis

.info-box[
**Data analysis** is a process of cleaning, transforming, inspecting and modelling data with the aim of extracting information.
]

<br>

* Data analysis includes:
  * exploratory data analysis,
  * confirmatory data analysis, and 
  * _initial data analysis_.
  
--


* Confirmatory data analysis is focussed on statistical inference and includes processes such as testing hypothesis, model selection, or predictive modelling... {{content}}

--
but today's focus will be on **_initial data analysis_**.

---


# Initial Data Analysis (IDA)

* There are various definitions of IDA, much like there are numerous definitions for EDA.
* Some people would be practicing IDA without realising that it is IDA.
* Or other cases, a different name is used to describe the same process, such as Chatfield (1985) referring to IDA also as **_"initial examination of data"_** and Cox & Snell (1981) as **_"preliminary data anlysis"_** and Rao (1983) as **_"cross-examination of data"_**.



.footnote[
Chatfield (1985) The Initial Examination of Data. *Journal of the Royal Statistical Society. Series A (General)* **148** <Br>
Cox & Snell (1981) Applied Statistics. *London: Chapman and Hall.*<br>
Rao (1983) Optimum balance between statistical theory and application in teaching. *Proc. of the First Int Conference on Teaching Statistics* 34-49
]

--

<br>

.monash-blue[**So what is IDA?**]



---

# What is IDA?

.info-box[
The two .monash-blue[main objectives for IDA] are:

<div style="padding-left: 40px;">
<ol>
<li> <b>data description</b>, and</li> 
<li> <b>model formulation</b>.</li>
</ol>
</div>
]
--


* **_IDA differs from the main analysis_** (i.e. usually fitting the model, conducting significance tests, making inferences or predictions). 
--


* **_IDA is often unreported_** in the data analysis reports or scientific papers due to it being "uninteresting" or "obvious".
--


* The role of **_the main analysis is to answer the intended question(s) that the data were collected for_**.
--


* Sometimes IDA alone is sufficient. 

---

# .circle[1] Data Description .font_small[Part 1/2]


* Data description should be one of the first steps in the data analysis to **_assess the structure and quality of the data_**.
--


* We refer them to occasionally as **_data sniffing_** or **_data scrutinizing_**.
--


* These include using common or domain knowledge to check if the recorded data have sensible values. 
--
E.g. 
  * Are positive values, e.g. height and weight, recorded as positive values with a plausible range?
--


  * If the data are counts, are the recorded values contain non-integer values?
--


  * For compositional data, do the values add up to 100% (or 1)? If not is that a measurement error or due to rounding? Or is another variable missing?

---

# .circle[1] Data Description .font_small[Part 2/2]

* In addition, numerical or graphical summaries may reveal that there is unwanted structure in the data. E.g.,
    * Does the treatment group have different demographic characteristics to the control group? 
    * Does the distribution of the data imply violations of assumptions for the main analysis?
--
* *Data sniffing* or *data scrutinizing* is a process that you get better at with practice and have familiarity with the domain area. 
--

* Aside from checking the _data structure_ or _data quality_, it's important to check how the data are understood by the computer, i.e. checking for _data type_ is also important. E.g.,
    * Was the date read in as character?
    * Was a factor read in as numeric?
    
    
---

class: nostripheader middle


# Next we'll see some _illustrative .blue[examples]_  and _.orange[cases] based on real data_ with some R codes

<Br>

* Note: that there are a variety of ways to do IDA & EDA and you don't need to prescribe to what we show you.
* Also see: [Staniak & Biecek (2019) "The Landscape of R Packages for Automated Exploratory Data Analysis" *R Journal* **11** (2)](https://journal.r-project.org/archive/2019/RJ-2019-033/RJ-2019-033.pdf)



---

class: font_smaller

# .blue[Example] .circle.bg-blue[1] Checking the data type .font_small[Part 1/2]

.grid[
.item[
`lecture3-example.xlsx`

<center>
<img src="images/lecture3-example.png" width = "400px">
</center>

]
.item[

```{r, echo = TRUE}
library(readxl)
library(here)
df <- read_excel(here("data/lecture3-example.xlsx"))
df
```


Any issues here?

]
]

---

class: font_smaller

# .blue[Example] .circle.bg-blue[1] Checking the data type .font_small[Part 2/2]

.grid[
.item[
```{r, echo = TRUE}
library(lubridate)
df %>% 
  mutate(id = as.factor(id),
         day = day(date),
         month = month(date),
         year = year(date)) %>% 
  select(-date)
```

]
.item[
* `id` is now a `factor` instead of `integer`
* `day`, `month` and `year` are now extracted from the `date`
* Is it okay now?

{{content}}

]
]

--

* In the United States, it's common to use the date format MM/DD/YYYY <a class="font_small black" href="https://twitter.com/statsgen/status/1257959369448161281">(gasps)</a>  while the rest of the world commonly use DD/MM/YYYY or YYYY/MM/DD.
{{content}}
--


* It's highly probable that the dates are 1st-5th March and not 3rd of Jan-May.
{{content}}
--


* You can validate this with other variables, say the temperature [here](https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/2010-3).


---

class: font_smaller

# .blue[Example] .circle.bg-blue[1] Checking the data type with R .font_small[Part 1/3]

.grid[.item[

* You can robustify your workflow by ensuring you have a check for the expected data type in your code.

```{r, echo = TRUE}
xlsx_df <- read_excel(here("data/lecture3-example.xlsx"),
                 col_types = c("text", "date", "text", "numeric")) %>% 
  mutate(id = as.factor(id), 
         date = as.character(date),
         date = as.Date(date, format = "%Y-%d-%m"))
# `read_csv` has a broader support for `col_types`
csv_df <- read_csv(here("data/lecture3-example.csv"),
                 col_types = cols(
                      id = col_factor(),
                      date = col_date(format = "%m/%d/%y"),
                      loc = col_character(),
                      temp = col_double()))
```

* The checks (or coercions) ensure that even if the data are updated, you can have some confidence that any data type error will be picked up before further analysis.

]
.item[




]
]


---

class: font_smaller

# .blue[Example] .circle.bg-blue[1] Checking the data type with R .font_small[Part 2/3]


You can have a quick glimpse of the data type with:

```{r, echo = TRUE}
dplyr::glimpse(xlsx_df)
dplyr::glimpse(csv_df)
```

---

class: font_smaller

# .blue[Example] .circle.bg-blue[1] Checking the data type with R .font_small[Part 3/3]

You can also visualise the data type with:

.grid[.item.border-right[
```{r, echo = TRUE}
library(visdat)
vis_dat(xlsx_df) + 
  scale_fill_discrete_qualitative()
```

]
.item[
```{r, echo = TRUE}
library(inspectdf)
inspect_types(xlsx_df) %>% 
  show_plot() + 
  scale_fill_discrete_qualitative()
```

]
]


---

class: font_smaller

# .blue[Example] .circle.bg-blue[2] Checking the data quality

.grid[
.item[
```{r, echo = TRUE}
df2 <- read_csv(here("data/lecture3-example2.csv"),
    col_types = cols(id = col_factor(),
                     date = col_date(format = "%m/%d/%y"),
                     loc = col_character(),
                     temp = col_double()))
df2
```


]
.item[
* Numerical or graphical summaries or even just eye-balling the data helps to uncover some data quality issues.
* Any issues here?
{{content}}

]
]

--
<br><br>
* There's a missing value in `loc`.
* Temperature is in Farenheit for New York but Celsius in Melbourne (you can validate this again using external sources).

---

class: font_smaller

# .orange[Case study] .circle.bg-orange[1]  Soybean study in Brazil .font_small[Part 1/3]



.scroll-800[
```{r, echo = TRUE, render=knitr::normal_print}
data("lehner.soybeanmold", package = "agridat")
skimr::skim(lehner.soybeanmold) #<<
```
]

<center>
scroll<br>
<i class="fas fa-angle-double-down"></i>
</center>

.footnote[
Lehner, M. S., Pethybridge, S. J., Meyer, M. C., & Del Ponte, E. M. (2016). Meta-analytic modelling of the incidence-yield and incidence-sclerotial production relationships in soybean white mould epidemics. _Plant Pathology_. doi:10.1111/ppa.12590
]

---

class: font_smaller

# .orange[Case study] .circle.bg-orange[1]  Soybean study in Brazil .font_small[Part 2/3]

.grid[.item.border-right[
```{r, echo = TRUE}
vis_miss(lehner.soybeanmold)
```
]
.item[
```{r, echo = TRUE, fig.width = 10}
inspect_na(lehner.soybeanmold) %>% 
  show_plot()
```


]]


---

class: font_smaller

# .orange[Case study] .circle.bg-orange[1]  Soybean study in Brazil .font_small[Part 3/3]

.grid[.item.border-right[

Checking if missing values have different yields:
```{r, echo = TRUE}
library(naniar) #<<
ggplot(lehner.soybeanmold, 
       aes(sclerotia, yield)) + 
  geom_miss_point() + #<<
  scale_color_discrete_qualitative()
```
]
.item[
Compare the new with old data:

```{r, echo = TRUE}
soy_old <- lehner.soybeanmold %>% 
  filter(year %in% 2010:2011)
soy_new <- lehner.soybeanmold %>% 
  filter(year == 2012)

inspect_cor(soy_old, soy_new) %>%  #<<
  show_plot() #<<
```

]
]

---

class: font_small

# .orange[Case study] .circle.bg-orange[2] Employment Data in Australia .font_small[Part 1/3]

Below is the data from ABS that shows the total number of people employed in a given month from February 1976 to December 2019 using the original time series.

<br>

```{r, cache = T, fig.height = 3.7, fig.width = 7}
library(readabs)
# lfs_1 <- read_abs("6202.0", tables = 1)  %>% 
#  separate_series()
employed <- read_abs(series_id = "A84423085A") %>% 
  mutate(month = lubridate::month(date),
         year = factor(lubridate::year(date))) %>% 
  filter(year != "2020") %>% 
  select(date, month, year, value) 
# Employed total ;  Persons ; original
# read_abs(series_id = "A84423043C") # seasonally adjusted
# A84423127L # trend
#glimpse(employed)
```


```{r, echo = TRUE}
glimpse(employed)
```

.footnote[
Australian Bureau of Statistics, 2020, Labour force, Australia, Table 01. Labour force status by Sex, Australia - Trend, Seasonally adjusted and Original, viewed `r Sys.Date()`, [<i class="fas  fa-link"></i>](https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/6202.0Jul%202020?OpenDocument)
]

---

# .orange[Case study] .circle.bg-orange[2]  Employment Data in Australia .font_small[Part 2/3]

Do you notice anything?

```{r, fig.height = 6, fig.width = 12}
employed  %>% 
  ggplot(aes(month, value, color = year)) + 
  geom_line() + 
  ggtitle("1978 Feb - 2019 Dec") + 
  scale_color_discrete_qualitative() 
```


--

Why do you think the number of people employed is going up each year?

---

# .orange[Case study] .circle.bg-orange[2]  Employment Data in Australia .font_small[Part 3/3]

.grid[.item[
```{r, fig.height = 8, fig.width = 6}
df3 <- employed  %>% 
  dplyr::filter(as.numeric(as.character(year)) > 2008) %>% 
  mutate(month = factor(month)) 
ggplot(df3, aes(month, value, group = year)) + 
  geom_line() + 
  geom_text(data = filter(df3, month==12) %>% 
              mutate(month = ifelse(year %in% c(2011, 2013), 14, month)), 
            aes(label = year), hjust = -0.4, size = 5) +
  ggtitle("2009 Jan - 2019 Dec") +
  coord_cartesian(clip = 'off') + 
  theme(plot.margin = unit(c(1,4,1,1), "lines")) 
  
```

]
.item[

{{content}}

]
]

--


* There's a suspicious change in August numbers from 2014.

```{r}
df3 %>% 
  filter(month %in% 8:9) %>% 
  pivot_wider(year, names_from = month) %>% 
  mutate(diff = `9` - `8`) %>% 
  ggplot(aes(year, diff)) + 
  geom_point() + 
  geom_line(group = 1) +
  guides(x = guide_axis(n.dodge = 2)) + 
  labs(y = "Difference (Sep - Aug)")
```

* A potential explanation for this is that there was a _change in the survey from 2014_. 


<div class="footnote" style="margin-left:-700px;padding-left:100px">
Also see https://robjhyndman.com/hyndsight/abs-seasonal-adjustment-2/
</div>


---

class: nostripheader middle


# Check if the _data collection_ method has been consistent

---

class: font_smaller

# .blue[Example] .circle.bg-blue[3] Experimental layout and data .font_small[Part 1/2]

```{r, eval = FALSE}
# to generate data that looks like it's non-randomised
rothamsted.brussels %>% 
  arrange(trt) %>% 
  mutate(row = rep(1:6, each = 8),
         col = rep(1:8, times = 6)) %>% 
  write_csv("data/lecture3-example3.csv")
```


`lecture3-example3.csv`
```{r, echo = TRUE}
df3 <- read_csv(here::here("data/lecture3-example3.csv"),
                col_types = cols(
                  row = col_factor(),
                  col = col_factor(),
                  yield = col_double(),
                  trt = col_factor(),
                  block = col_factor()))
```
.scroll-300[
```{r, echo = TRUE, render = knitr::normal_print}
skimr::skim(df3)
```
]


---


class: font_smaller

# .blue[Example] .circle.bg-blue[3] Experimental layout and data .font_small[Part 2/2]


.grid[
.item[
```{r}
ggplot(df3, aes(col, row, fill = trt)) + 
  geom_tile(color = "black", size = 2) + 
  coord_equal() +
  scale_fill_discrete_qualitative()

ggplot(df3, aes(col, row, fill = yield)) + 
  geom_tile(color = "black", size = 2) + 
  coord_equal() +
  scale_fill_continuous_sequential(palette = "Greens 3")
```

]
.item[



* The experiment tests the effects of 9 fertilizer treatments on the yield of brussel sprouts on a field laid out in a rectangular array of 6 rows and 8 columns.  

```{r, fig.width = 8, fig.height = 3}
df3 %>% 
  mutate(trt = fct_reorder(trt, yield)) %>% 
  ggplot(aes(trt, yield)) + 
  geom_point(size = 4, alpha = 1 / 2) + 
  guides(x = guide_axis(n.dodge = 2))
```

* High sulphur and high manure seems to best for the yield of brussel sprouts.
* Any issues here?

]
]


---


class: nostripheader middle


# Check if experimental layout given in the data and the description match 

In particular, have a check with a plot to see if treatments are _randomised_. 


---

class: nostripheader middle

# Next we'll have a look at the

# &emsp;&emsp;&emsp;&emsp; <span class="circle bg-blue" style="color:black">2</span> Model formulation


---

# Resources


- Chatfield (1985) “The Initial Examination of Data.” *Journal of the Royal Statistical Society. Series A (General)* **148** (3) 214-253
- Huebner M, le Cessie S, Schmidt CO, Vach W (2018) "A contemporary conceptual framework for initial data analysis." *Observational Studies* **4** 171-192 
- Staniak, Mateusz & Biecek, Przemysław (2019) "The Landscape of R Packages for Automated Exploratory Data Analysis" *R Journal* **11** (2) 
- Data coding using [`tidyverse` suite of R packages](https://www.tidyverse.org) 
- Slides constructed with [`xaringan`](https://github.com/yihui/xaringan), [remark.js](https://remarkjs.com), [`knitr`](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).

---

```{r endslide, child="components/endslide.Rmd"}
```
